{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__DEVICE = torch.device(\"cuda\")\n",
    "# __DEVICE = torch.device(\"cpu\")\n",
    "__INPUT_DIM = 762\n",
    "__OUTPUT_DIM = 4096\n",
    "__BATCH_SIZE = 128\n",
    "__SPARSITY = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def get_ffi_structure(mod: nn.Linear, sparsity: float) -> nn.Linear:\n",
    "    n_zeros = int(mod.weight.numel() * (sparsity))\n",
    "    n_zeros_per_neuron = n_zeros // mod.weight.shape[0]\n",
    "    for idx, neuron in enumerate(mod.weight):\n",
    "        rand_idx = torch.randperm(n=len(neuron))\n",
    "        mod.weight[idx, rand_idx[:n_zeros_per_neuron-1]] = 0\n",
    "    assert_ffi(mod)\n",
    "    print_sparsity(mod)\n",
    "    return mod\n",
    "\n",
    "def assert_ffi(mod: nn.Linear):\n",
    "    ffi = (mod.weight[0]!=0).sum()\n",
    "    for n in mod.weight:\n",
    "        assert (n!=0).sum()==ffi\n",
    "\n",
    "def print_sparsity(mod: nn.Linear):\n",
    "    print(f\"Mod sparsity: {1-((mod.weight!=0).sum()/mod.weight.numel()).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod sparsity: 0.9580\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(in_features=__INPUT_DIM, out_features=__OUTPUT_DIM, device=__DEVICE)\n",
    "sparse_linear = get_ffi_structure(linear, __SPARSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sparse_linear.weight[0]!=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 762])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(size=(__BATCH_SIZE, __INPUT_DIM), device=__DEVICE)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFILinearNaive(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        dtype: torch.typename = torch.float32,\n",
    "        transpose: bool = True,\n",
    "        vectorize: bool = False,\n",
    "        index_dtype: torch.typename = torch.int32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if dtype is None:\n",
    "            dtype = module.weight.dtype\n",
    "\n",
    "        self.transpose = transpose\n",
    "        with torch.no_grad():\n",
    "            fine_grained_idx = (module.weight != 0).to(\n",
    "                torch.bool\n",
    "            )\n",
    "            _, self.input_mask = fine_grained_idx.nonzero(as_tuple=True)\n",
    "            self.input_mask = self.input_mask.reshape(\n",
    "                shape=(module.weight.shape[0], -1)\n",
    "            ).to(index_dtype)\n",
    "            weight = module.weight.detach().type(dtype)\n",
    "            weight = torch.clone(\n",
    "                weight[fine_grained_idx]\n",
    "                .reshape(shape=(weight.shape[0], -1))\n",
    "                .detach()\n",
    "                .type(dtype)\n",
    "            )\n",
    "            # padding to multiple of 4\n",
    "            if vectorize:\n",
    "                pad = (\n",
    "                    self.input_mask.shape[1] + 3\n",
    "                ) // 4 * 4 - self.input_mask.shape[1]\n",
    "                self.input_mask = F.pad(self.input_mask, [0, pad])\n",
    "                weight = F.pad(weight, [0, pad])\n",
    "\n",
    "            self.condensed_weight = nn.Parameter(\n",
    "                weight,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "\n",
    "            if hasattr(module, \"bias\"):\n",
    "                self.bias = nn.Parameter(\n",
    "                    torch.clone(\n",
    "                        module.bias.detach().type(dtype)\n",
    "                    ),\n",
    "                    requires_grad=False,\n",
    "                )\n",
    "            else:\n",
    "                self.register_parameter(\"bias\", None)\n",
    "            self.to(module.weight.device)\n",
    "            self.input_mask.to(module.weight.device)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        output = torch.empty(size=(input.shape[0], self.condensed_weight.shape[0]), device=x.device)\n",
    "        output_size, nnz_el_per_neuron = self.input_mask.shape\n",
    "        for batch in range(input.shape[0]):\n",
    "            for out in range(output_size):\n",
    "                output[batch, out] = self.bias[out]\n",
    "                for index in range(nnz_el_per_neuron):\n",
    "                    output[batch, out] += input[batch, self.input_mask[out, index]] * self.condensed_weight[out, index]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffi_naive = FFILinearNaive(sparse_linear)\n",
    "# sparse_linear(x).allclose(ffi_naive(x), atol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FFILinearVmap(FFILinearNaive):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        dtype: torch.typename = torch.float32,\n",
    "        transpose: bool = True,\n",
    "        vectorize: bool = False,\n",
    "        index_dtype: torch.typename = torch.int32,\n",
    "    ):\n",
    "        super().__init__(module, dtype, transpose, vectorize, index_dtype)\n",
    "    \n",
    "    def batch_kernel(self, input, input_masks, weights, biases):\n",
    "        return torch.vmap(self.output_kernel, in_dims=(None, 0, 0, 0))(input, input_masks, weights, biases)\n",
    "\n",
    "    def output_kernel(self, input, input_mask, weight, bias):\n",
    "        return bias + torch.sum(input[input_mask] * weight)\n",
    "\n",
    "    # @override\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        return torch.vmap(self.batch_kernel, in_dims=(0, None, None, None), out_dims=0)(input, self.input_mask, self.condensed_weight, self.bias)\n",
    "\n",
    "ffi_vmap = FFILinearVmap(sparse_linear, vectorize=True)\n",
    "ffi_vmap(x).allclose(sparse_linear(x), atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffi_compiled = torch.compile(ffi_vmap, mode=\"reduce-overhead\")\n",
    "ffi_compiled = torch.compile(ffi_vmap, mode=\"max-autotune\")\n",
    "for _ in range(10):\n",
    "    _ = ffi_compiled(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERS = 10\n",
    "\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    for _ in range(10):\n",
    "        _ = fn()\n",
    "    start.record()\n",
    "    for _ in range(N_ITERS):\n",
    "        result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense: 0.0010383360385894775\n",
      "FFI_VMAP: 0.006908927917480469\n",
      "FFI_Compiled: 0.006913023948669434\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"Dense:\", timed(lambda: linear(x))[1])\n",
    "    # print(\"FFI_Naive:\", timed(lambda: ffi_naive(x))[1])\n",
    "    print(\"FFI_VMAP:\", timed(lambda: ffi_vmap(x))[1])\n",
    "    print(\"FFI_Compiled:\", timed(lambda: ffi_compiled(x))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffi_vmap.condensed_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 22,  36,  58,  71,  77, 112, 156, 175, 219, 233, 238, 289, 291, 293,\n",
       "        321, 328, 351, 427, 435, 446, 455, 488, 503, 505, 506, 529, 537, 614,\n",
       "        634, 702, 716, 753], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffi_vmap.input_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffi_compiled.input_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 762])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:32, ffi_compiled.input_mask[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Triton\n",
    "os.environ[\"TRITON_INTERPRET\"] = \"1\"\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "@triton.jit\n",
    "def ffi_triton(\n",
    "    # Output / Input pointers\n",
    "    output_p,\n",
    "    input_p,\n",
    "    # Pointers to weights, bias, and mask\n",
    "    weight_p,\n",
    "    bias_p,\n",
    "    mask_p,\n",
    "    # number of outputs channels, input channels, and batch_size\n",
    "    n_out: tl.constexpr,\n",
    "    n_in: tl.constexpr,\n",
    "    n_batch: tl.constexpr,\n",
    "    n_weights: tl.constexpr,\n",
    "    # Number of nnz_el per neuron and grid block size\n",
    "    FFI_PER_NEURON: tl.constexpr,\n",
    "    BLOCK_SIZE_X: tl.constexpr,\n",
    "    BLOCK_SIZE_Y: tl.constexpr,\n",
    "):\n",
    "    block_idx_x, block_idx_y = tl.program_id(axis=0), tl.program_id(axis=1)\n",
    "    batch_idx = block_idx_x * BLOCK_SIZE_X\n",
    "    unit_idx = block_idx_y * BLOCK_SIZE_Y\n",
    "    # We want this kernel invocation to compute the first 32 batches and 32 outputs\n",
    "\n",
    "    batch_offsets = batch_idx + tl.arange(0, BLOCK_SIZE_X)\n",
    "    batch_mask = batch_offsets < n_batch\n",
    "    # Load up input from batches up to batch_idx * block size\n",
    "\n",
    "    unit_offsets = unit_idx + tl.arange(0, BLOCK_SIZE_Y)\n",
    "    unit_mask = unit_offsets < n_out * n_batch\n",
    "    # output units up ot block_size_y * current idx. \n",
    "    \n",
    "    mask_offsets = tl.expand_dims(\n",
    "        unit_offsets, 1\n",
    "    ) * FFI_PER_NEURON + tl.expand_dims(tl.arange(0, FFI_PER_NEURON), 0)\n",
    "    # We need to load masks for the current output units and all FFI weights\n",
    "    mask_mask = mask_offsets < n_weights\n",
    "    weight_offsets = (\n",
    "        tl.expand_dims(tl.arange(0, FFI_PER_NEURON), 1)\n",
    "        + tl.expand_dims(unit_offsets, 0) * FFI_PER_NEURON\n",
    "    )\n",
    "    # Similarly, we load weights for current output units and all FFI weights, but weights have been transposed\n",
    "    weight_mask = weight_offsets < n_weights\n",
    "\n",
    "    output_offsets = tl.expand_dims(\n",
    "        batch_offsets * BLOCK_SIZE_X, 1\n",
    "    ) + tl.expand_dims(unit_offsets, 0)\n",
    "    output_mask = output_offsets < n_batch * n_out\n",
    "    \n",
    "    # Now, we need to broadcast input by mask and iteratively write out to output???\n",
    "    for _ in range(0, BLOCK_SIZE_Y):\n",
    "        \n",
    "\n",
    "    bias = tl.load(bias_p + unit_offsets, mask=unit_mask)\n",
    "    output = tl.load(output_p + output_offsets, output_mask)\n",
    "    output += bias\n",
    "    weights = tl.load(weight_p + weight_offsets, mask=weight_mask)\n",
    "    mask = tl.load(mask_p + mask_offsets, mask=mask_mask)\n",
    "\n",
    "    input_offset = tl.expand_dims(batch_offsets, 1) * n_in + mask\n",
    "    input_mask = input_offset < n_in * n_batch\n",
    "    inputs = tl.load(input_p + input_offset, input_mask)\n",
    "    print(inputs)\n",
    "    print(weights)\n",
    "    print(bias)\n",
    "    # output+=tl.dot(inputs, weights, allow_tf32=False)\n",
    "    # tl.store(output_p + output_offsets, output, output_mask)\n",
    "\n",
    "\n",
    "# output = torch.zeros(size=(__BATCH_SIZE, __OUTPUT_DIM), device=__DEVICE)\n",
    "output = torch.zeros(size=(32, 32), device=__DEVICE)\n",
    "input = x[:32]\n",
    "weight = ffi_vmap.condensed_weight.T[:,:32] # shape is now ffi, output\n",
    "bias = ffi_vmap.bias[:32]\n",
    "mask = ffi_vmap.input_mask[:, :32]\n",
    "n_elements = input.numel()\n",
    "n_weights = weight.numel()\n",
    "FFI_PER_NEURON = weight.shape[0]  # first dim is now ffi\n",
    "BLOCK_SIZE_X=32\n",
    "BLOCK_SIZE_Y=32\n",
    "n_out = __OUTPUT_DIM\n",
    "n_in = __INPUT_DIM\n",
    "n_batch = __BATCH_SIZE\n",
    "grid = triton.cdiv(input.shape[0], BLOCK_SIZE_X), triton.cdiv(weight.shape[1], BLOCK_SIZE_Y)  # 32 threads per grid block \n",
    "print(grid)\n",
    "ffi_triton[grid](output, input, weight, bias, mask, n_out, n_in, n_batch, n_weights, FFI_PER_NEURON, BLOCK_SIZE_X, BLOCK_SIZE_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "[[0.28271836 0.20015647 0.01879376 ... 0.22647431 0.6467432  0.1392649 ]\n",
      " [0.94857585 0.8641366  0.8750439  ... 0.739289   0.43764648 0.61978006]\n",
      " [0.53988975 0.5642546  0.39189672 ... 0.8288116  0.8856129  0.17456578]\n",
      " ...\n",
      " [0.31094283 0.85903955 0.26372623 ... 0.83719045 0.82869154 0.7847737 ]\n",
      " [0.7128974  0.5074023  0.6337079  ... 0.52218926 0.1635361  0.33997655]\n",
      " [0.12492803 0.5038944  0.60762745 ... 0.33695993 0.93491524 0.4055208 ]]\n",
      "[[ 0.0261482  -0.00396388 -0.0059791  ...  0.02332326 -0.00391128\n",
      "  -0.03106531]\n",
      " [ 0.02015613 -0.0085853   0.01332369 ...  0.02736109  0.03410102\n",
      "   0.0103325 ]\n",
      " [ 0.00322715 -0.03347414 -0.00471053 ... -0.00461934  0.03265392\n",
      "   0.00083682]\n",
      " ...\n",
      " [ 0.00548304 -0.00404497  0.00299763 ... -0.03259914 -0.00229209\n",
      "   0.03327067]\n",
      " [ 0.00554703 -0.03012603  0.0340563  ...  0.00013082 -0.03185382\n",
      "  -0.03150038]\n",
      " [ 0.02553615 -0.00307607  0.03510918 ...  0.02092469 -0.00323277\n",
      "  -0.03095286]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22  36  58 ... 702 716 753]\n",
      " [ 35  84 127 ... 630 707 709]\n",
      " [ 48  63  74 ... 651 667 727]\n",
      " ...\n",
      " [  4  10  36 ... 741 745 752]\n",
      " [  1  15  61 ... 689 703 746]\n",
      " [ 11  83  89 ... 679 701 758]]\n",
      "[constexpr[32], constexpr[32]]\n",
      "[[   22    36    58 ...   702   716   753]\n",
      " [  797   846   889 ...  1392  1469  1471]\n",
      " [ 1572  1587  1598 ...  2175  2191  2251]\n",
      " ...\n",
      " [22102 22108 22134 ... 22839 22843 22850]\n",
      " [22861 22875 22921 ... 23549 23563 23606]\n",
      " [23633 23705 23711 ... 24301 24323 24380]]\n",
      "[constexpr[32], constexpr[32]]\n",
      "[[0.28271836 0.20015647 0.01879376 ... 0.22647431 0.6467432  0.1392649 ]\n",
      " [0.94857585 0.8641366  0.8750439  ... 0.739289   0.43764648 0.61978006]\n",
      " [0.53988975 0.5642546  0.39189672 ... 0.8288116  0.8856129  0.17456578]\n",
      " ...\n",
      " [0.31094283 0.85903955 0.26372623 ... 0.83719045 0.82869154 0.7847737 ]\n",
      " [0.7128974  0.5074023  0.6337079  ... 0.52218926 0.1635361  0.33997655]\n",
      " [0.12492803 0.5038944  0.60762745 ... 0.33695993 0.93491524 0.4055208 ]]\n",
      "[[0.28271836 0.20015647 0.01879376 ... 0.22647431 0.6467432  0.1392649 ]\n",
      " [0.94857585 0.8641366  0.8750439  ... 0.739289   0.43764648 0.61978006]\n",
      " [0.53988975 0.5642546  0.39189672 ... 0.8288116  0.8856129  0.17456578]\n",
      " ...\n",
      " [0.31094283 0.85903955 0.26372623 ... 0.83719045 0.82869154 0.7847737 ]\n",
      " [0.7128974  0.5074023  0.6337079  ... 0.52218926 0.1635361  0.33997655]\n",
      " [0.12492803 0.5038944  0.60762745 ... 0.33695993 0.93491524 0.4055208 ]]\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2200351/2953876125.py\", line 85, in <module>\n",
      "    ffi_triton[grid](output, input, weight, bias, mask, n_out, n_in, n_batch, n_weights, FFI_PER_NEURON, BLOCK_SIZE_X, BLOCK_SIZE_Y)\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/triton/runtime/interpreter.py\", line 511, in __call__\n",
      "    self.fn(**args)\n",
      "  File \"/tmp/ipykernel_2200351/2953876125.py\", line 64, in ffi_triton\n",
      "    print(bias)\n",
      "  File \"/tmp/ipykernel_2200351/2953876125.py\", line 64, in ffi_triton\n",
      "    print(bias)\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1457, in _pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 701, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1152, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1135, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 312, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2070, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2106, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/home/mike/accel-snn/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1150, in get_records\n",
      "    mod = inspect.getmodule(cf.tb_frame)\n",
      "  File \"/home/mike/miniconda3/envs/py310/lib/python3.10/inspect.py\", line 875, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/mike/miniconda3/envs/py310/lib/python3.10/inspect.py\", line 844, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/mike/miniconda3/envs/py310/lib/python3.10/inspect.py\", line 820, in getsourcefile\n",
      "    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n",
      "  File \"/home/mike/miniconda3/envs/py310/lib/python3.10/inspect.py\", line 820, in <genexpr>\n",
      "    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n",
      "AttributeError: 'function' object has no attribute 'endswith'\n"
     ]
    }
   ],
   "source": [
    "## Triton\n",
    "os.environ[\"TRITON_INTERPRET\"] = \"1\"\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "@triton.jit\n",
    "def ffi_triton(\n",
    "    # Output / Input pointers\n",
    "    output_p,\n",
    "    input_p,\n",
    "    # Pointers to weights, bias, and mask\n",
    "    weight_p,\n",
    "    bias_p,\n",
    "    mask_p,\n",
    "    # number of outputs channels, input channels, and batch_size\n",
    "    n_out: tl.constexpr,\n",
    "    n_in: tl.constexpr,\n",
    "    n_batch: tl.constexpr,\n",
    "    n_weights: tl.constexpr,\n",
    "    # Number of nnz_el per neuron and grid block size\n",
    "    FFI_PER_NEURON: tl.constexpr,\n",
    "    BLOCK_SIZE_X: tl.constexpr,\n",
    "    BLOCK_SIZE_Y: tl.constexpr,\n",
    "):\n",
    "    block_idx_x, block_idx_y = tl.program_id(axis=0), tl.program_id(axis=1)\n",
    "    batch_idx = block_idx_x * BLOCK_SIZE_X\n",
    "    unit_idx = block_idx_y * BLOCK_SIZE_Y\n",
    "\n",
    "    batch_offsets = batch_idx + tl.arange(0, BLOCK_SIZE_X)\n",
    "\n",
    "    unit_offsets = unit_idx + tl.arange(0, BLOCK_SIZE_Y)\n",
    "    unit_mask = unit_offsets < n_out * n_batch\n",
    "\n",
    "    mask_offsets = tl.expand_dims(\n",
    "        unit_offsets, 1\n",
    "    ) * FFI_PER_NEURON + tl.expand_dims(tl.arange(0, FFI_PER_NEURON), 0)\n",
    "    mask_mask = mask_offsets < n_weights\n",
    "    weight_offsets = (\n",
    "        tl.expand_dims(tl.arange(0, FFI_PER_NEURON), 1)\n",
    "        + tl.expand_dims(unit_offsets, 0) * FFI_PER_NEURON\n",
    "    )\n",
    "    weight_mask = weight_offsets < n_weights\n",
    "\n",
    "    output_offsets = tl.expand_dims(\n",
    "        batch_offsets * BLOCK_SIZE_X, 1\n",
    "    ) + tl.expand_dims(unit_offsets, 0)\n",
    "    output_mask = output_offsets < n_batch * n_out\n",
    "\n",
    "    bias = tl.load(bias_p + unit_offsets, mask=unit_mask)\n",
    "    output = tl.load(output_p + output_offsets, output_mask)\n",
    "    output += bias\n",
    "    weights = tl.load(weight_p + weight_offsets, mask=weight_mask)\n",
    "    mask = tl.load(mask_p + mask_offsets, mask=mask_mask)\n",
    "\n",
    "    input_offset = tl.expand_dims(batch_offsets, 1) * n_in + mask\n",
    "    input_mask = input_offset < n_in * n_batch\n",
    "    inputs = tl.load(input_p + input_offset, input_mask)\n",
    "    print(inputs)\n",
    "    print(weights)\n",
    "    print(bias)\n",
    "    # output+=tl.dot(inputs, weights, allow_tf32=False)\n",
    "    # tl.store(output_p + output_offsets, output, output_mask)\n",
    "\n",
    "\n",
    "# output = torch.zeros(size=(__BATCH_SIZE, __OUTPUT_DIM), device=__DEVICE)\n",
    "output = torch.zeros(size=(32, 32), device=__DEVICE)\n",
    "input = x[:32]\n",
    "weight = ffi_vmap.condensed_weight.T[:,:32] # shape is now ffi, output\n",
    "bias = ffi_vmap.bias[:32]\n",
    "mask = ffi_vmap.input_mask[:, :32]\n",
    "n_elements = input.numel()\n",
    "n_weights = weight.numel()\n",
    "FFI_PER_NEURON = weight.shape[0]  # first dim is now ffi\n",
    "BLOCK_SIZE_X=32\n",
    "BLOCK_SIZE_Y=32\n",
    "n_out = __OUTPUT_DIM\n",
    "n_in = __INPUT_DIM\n",
    "n_batch = __BATCH_SIZE\n",
    "grid = triton.cdiv(input.shape[0], BLOCK_SIZE_X), triton.cdiv(weight.shape[1], BLOCK_SIZE_Y)  # 32 threads per grid block \n",
    "print(grid)\n",
    "ffi_triton[grid](output, input, weight, bias, mask, n_out, n_in, n_batch, n_weights, FFI_PER_NEURON, BLOCK_SIZE_X, BLOCK_SIZE_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0471,  0.0032,  0.1054,  ..., -0.0047,  0.0056, -0.0140],\n",
       "        [ 0.1094, -0.0223,  0.0566,  ...,  0.0500,  0.0528, -0.0418],\n",
       "        [ 0.1216, -0.0431,  0.0571,  ..., -0.0619,  0.0593, -0.0010],\n",
       "        ...,\n",
       "        [ 0.1315, -0.0106,  0.1529,  ...,  0.0126,  0.0128, -0.0392],\n",
       "        [ 0.0667, -0.0203,  0.0803,  ..., -0.0217,  0.0624, -0.0229],\n",
       "        [ 0.1379, -0.0187,  0.0572,  ...,  0.0335,  0.0508, -0.0147]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0471, -0.0391,  0.0182,  ...,  0.0366,  0.0762,  0.0381],\n",
       "        [ 0.0930, -0.0223,  0.0981,  ...,  0.0280,  0.0720,  0.0642],\n",
       "        [ 0.1260, -0.0361,  0.0571,  ...,  0.0188,  0.0824, -0.0046],\n",
       "        ...,\n",
       "        [ 0.1381,  0.0008,  0.0923,  ...,  0.0060,  0.1120,  0.0091],\n",
       "        [ 0.1127, -0.0196,  0.1390,  ...,  0.0488,  0.0676,  0.0181],\n",
       "        [ 0.1553,  0.0510,  0.1138,  ...,  0.0455,  0.1527,  0.0146]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffi_compiled(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4096])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8160/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8160, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output!=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedFanInCuda(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        dtype: torch.typename = torch.float32,\n",
    "        transpose: bool = True,\n",
    "        vectorize: bool = False,\n",
    "        index_dtype: torch.typename = torch.int32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if dtype is None:\n",
    "            dtype = module.weight.dtype\n",
    "\n",
    "        self.transpose = transpose\n",
    "        with torch.no_grad():\n",
    "            active_neuron_idx = module.weight.sum(dim=1) != 0\n",
    "            fine_grained_idx = (module.weight[active_neuron_idx] != 0).to(\n",
    "                torch.bool\n",
    "            )\n",
    "            _, self.input_mask = fine_grained_idx.nonzero(as_tuple=True)\n",
    "            self.input_mask = self.input_mask.reshape(\n",
    "                shape=(module.weight[active_neuron_idx].shape[0], -1)\n",
    "            ).to(index_dtype)\n",
    "            weight = module.weight[active_neuron_idx].detach().type(dtype)\n",
    "            weight = torch.clone(\n",
    "                weight[fine_grained_idx]\n",
    "                .reshape(shape=(weight.shape[0], -1))\n",
    "                .detach()\n",
    "                .type(dtype)\n",
    "            )\n",
    "            # padding to multiple of 4\n",
    "            if vectorize:\n",
    "                pad = (\n",
    "                    self.input_mask.shape[1] + 3\n",
    "                ) // 4 * 4 - self.input_mask.shape[1]\n",
    "                self.input_mask = F.pad(self.input_mask, [0, pad])\n",
    "                weight = F.pad(weight, [0, pad])\n",
    "\n",
    "            self.condensed_weight = nn.Parameter(\n",
    "                weight,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "\n",
    "            if hasattr(module, \"bias\"):\n",
    "                self.bias = nn.Parameter(\n",
    "                    torch.clone(\n",
    "                        module.bias[active_neuron_idx].detach().type(dtype)\n",
    "                    ),\n",
    "                    requires_grad=False,\n",
    "                )\n",
    "            else:\n",
    "                self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return ffi_mul(\n",
    "            input,\n",
    "            self.condensed_weight,\n",
    "            self.input_mask,\n",
    "            self.bias,\n",
    "            transpose=self.transpose,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondensedLinearFineGrained(nn.Module):\n",
    "    def __init__(\n",
    "        self, module: nn.Module, dtype: torch.typename = torch.float32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if dtype is None:\n",
    "            dtype = module.weight.dtype\n",
    "        with torch.no_grad():\n",
    "            active_neuron_idx = module.weight.sum(dim=1) != 0\n",
    "            fine_grained_idx = (module.weight[active_neuron_idx] != 0).to(\n",
    "                torch.bool\n",
    "            )\n",
    "            _, self.input_mask = fine_grained_idx.nonzero(as_tuple=True)\n",
    "            self.input_mask = self.input_mask.reshape(\n",
    "                shape=(module.weight[active_neuron_idx].shape[0], -1)\n",
    "            )\n",
    "            self.input_mask = self.input_mask.to(torch.int32)\n",
    "            weight = module.weight[active_neuron_idx].detach().type(dtype)\n",
    "            self.condensed_weight = nn.Parameter(\n",
    "                torch.clone(\n",
    "                    weight[fine_grained_idx]\n",
    "                    .reshape(shape=(weight.shape[0], -1))\n",
    "                    .detach()\n",
    "                    .type(dtype)\n",
    "                ),\n",
    "                requires_grad=False,\n",
    "            )\n",
    "            if hasattr(module, \"bias\"):\n",
    "                self.bias = nn.Parameter(\n",
    "                    torch.clone(\n",
    "                        module.bias[active_neuron_idx].detach().type(dtype)\n",
    "                    ),\n",
    "                    requires_grad=False,\n",
    "                )\n",
    "            else:\n",
    "                self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return (\n",
    "            torch.sum(\n",
    "                self.condensed_weight * input[..., self.input_mask],\n",
    "                dim=input.dim(),\n",
    "            )\n",
    "            + self.bias\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
