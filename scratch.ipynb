{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__DEVICE = torch.device(\"cuda\")\n",
    "# __DEVICE = torch.device(\"cpu\")\n",
    "__INPUT_DIM = 762\n",
    "__OUTPUT_DIM = 4096\n",
    "__BATCH_SIZE = 128\n",
    "__SPARSITY = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def get_ffi_structure(mod: nn.Linear, sparsity: float) -> nn.Linear:\n",
    "    n_zeros = int(mod.weight.numel() * (sparsity))\n",
    "    n_zeros_per_neuron = n_zeros // mod.weight.shape[0]\n",
    "    for idx, neuron in enumerate(mod.weight):\n",
    "        rand_idx = torch.randperm(n=len(neuron))\n",
    "        mod.weight[idx, rand_idx[:n_zeros_per_neuron-1]] = 0\n",
    "    assert_ffi(mod)\n",
    "    print_sparsity(mod)\n",
    "    return mod\n",
    "\n",
    "def assert_ffi(mod: nn.Linear):\n",
    "    ffi = (mod.weight[0]!=0).sum()\n",
    "    for n in mod.weight:\n",
    "        assert (n!=0).sum()==ffi\n",
    "\n",
    "def print_sparsity(mod: nn.Linear):\n",
    "    print(f\"Mod sparsity: {1-((mod.weight!=0).sum()/mod.weight.numel()).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod sparsity: 0.9580\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(in_features=__INPUT_DIM, out_features=__OUTPUT_DIM, device=__DEVICE)\n",
    "sparse_linear = get_ffi_structure(linear, __SPARSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sparse_linear.weight[0]!=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 762])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(size=(__BATCH_SIZE, __INPUT_DIM), device=__DEVICE)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFILinearNaive(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        dtype: torch.typename = torch.float32,\n",
    "        transpose: bool = True,\n",
    "        vectorize: bool = False,\n",
    "        index_dtype: torch.typename = torch.int32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if dtype is None:\n",
    "            dtype = module.weight.dtype\n",
    "\n",
    "        self.transpose = transpose\n",
    "        with torch.no_grad():\n",
    "            fine_grained_idx = (module.weight != 0).to(\n",
    "                torch.bool\n",
    "            )\n",
    "            _, self.input_mask = fine_grained_idx.nonzero(as_tuple=True)\n",
    "            self.input_mask = self.input_mask.reshape(\n",
    "                shape=(module.weight.shape[0], -1)\n",
    "            ).to(index_dtype)\n",
    "            weight = module.weight.detach().type(dtype)\n",
    "            weight = torch.clone(\n",
    "                weight[fine_grained_idx]\n",
    "                .reshape(shape=(weight.shape[0], -1))\n",
    "                .detach()\n",
    "                .type(dtype)\n",
    "            )\n",
    "            # padding to multiple of 4\n",
    "            if vectorize:\n",
    "                pad = (\n",
    "                    self.input_mask.shape[1] + 3\n",
    "                ) // 4 * 4 - self.input_mask.shape[1]\n",
    "                self.input_mask = F.pad(self.input_mask, [0, pad])\n",
    "                weight = F.pad(weight, [0, pad])\n",
    "\n",
    "            self.condensed_weight = nn.Parameter(\n",
    "                weight,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "\n",
    "            if hasattr(module, \"bias\"):\n",
    "                self.bias = nn.Parameter(\n",
    "                    torch.clone(\n",
    "                        module.bias.detach().type(dtype)\n",
    "                    ),\n",
    "                    requires_grad=False,\n",
    "                )\n",
    "            else:\n",
    "                self.register_parameter(\"bias\", None)\n",
    "            self.to(module.weight.device)\n",
    "            self.input_mask.to(module.weight.device)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        output = torch.empty(size=(input.shape[0], self.condensed_weight.shape[0]), device=x.device)\n",
    "        output_size, nnz_el_per_neuron = self.input_mask.shape\n",
    "        for batch in range(input.shape[0]):\n",
    "            for out in range(output_size):\n",
    "                output[batch, out] = self.bias[out]\n",
    "                for index in range(nnz_el_per_neuron):\n",
    "                    output[batch, out] += input[batch, self.input_mask[out, index]] * self.condensed_weight[out, index]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffi_naive = FFILinearNaive(sparse_linear)\n",
    "# sparse_linear(x).allclose(ffi_naive(x), atol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FFILinearVmap(FFILinearNaive):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        dtype: torch.typename = torch.float32,\n",
    "        transpose: bool = True,\n",
    "        vectorize: bool = False,\n",
    "        index_dtype: torch.typename = torch.int32,\n",
    "    ):\n",
    "        super().__init__(module, dtype, transpose, vectorize, index_dtype)\n",
    "    \n",
    "    def batch_kernel(self, input, input_masks, weights, biases):\n",
    "        return torch.vmap(self.output_kernel, in_dims=(None, 0, 0, 0))(input, input_masks, weights, biases)\n",
    "\n",
    "    def output_kernel(self, input, input_mask, weight, bias):\n",
    "        return bias + torch.sum(input[input_mask] * weight)\n",
    "\n",
    "    # @override\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        return torch.vmap(self.batch_kernel, in_dims=(0, None, None, None), out_dims=0)(x, self.input_mask, self.condensed_weight, self.bias)\n",
    "\n",
    "ffi_vmap = FFILinearVmap(sparse_linear, vectorize=True)\n",
    "ffi_vmap(x).allclose(sparse_linear(x), atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffi_compiled = torch.compile(ffi_vmap, mode=\"reduce-overhead\")\n",
    "ffi_compiled = torch.compile(ffi_vmap, mode=\"max-autotune\")\n",
    "for _ in range(10):\n",
    "    _ = ffi_compiled(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERS = 10\n",
    "\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    for _ in range(10):\n",
    "        _ = fn()\n",
    "    start.record()\n",
    "    for _ in range(N_ITERS):\n",
    "        result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense: 0.0010373120307922363\n",
      "FFI_VMAP: 0.006914048194885254\n",
      "FFI_Compiled: 0.006918144226074219\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"Dense:\", timed(lambda: linear(x))[1])\n",
    "    # print(\"FFI_Naive:\", timed(lambda: ffi_naive(x))[1])\n",
    "    print(\"FFI_VMAP:\", timed(lambda: ffi_vmap(x))[1])\n",
    "    print(\"FFI_Compiled:\", timed(lambda: ffi_compiled(x))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffi_vmap.condensed_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19,  26,  27,  30,  79,  84, 137, 157, 164, 190, 285, 290, 330, 418,\n",
       "        431, 434, 447, 487, 555, 564, 583, 603, 607, 630, 637, 657, 662, 697,\n",
       "        702, 708, 712, 737], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffi_vmap.input_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<triton.compiler.compiler.CompiledKernel at 0x7f13e6c44370>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Triton\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "os.environ[\"TRITON_INTERPRET\"] = \"0\"\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "@triton.jit\n",
    "def ffi_triton(\n",
    "    # Output / Input pointers\n",
    "    output_p,\n",
    "    input_p,\n",
    "    # Pointers to weights, bias, and mask\n",
    "    weight_p,\n",
    "    bias_p,\n",
    "    mask_p,\n",
    "    # number of outputs channels, input channels, and batch_size\n",
    "    n_out: tl.constexpr,\n",
    "    n_in: tl.constexpr,\n",
    "    n_batch: tl.constexpr,\n",
    "    n_weights: tl.constexpr,\n",
    "    # Number of nnz_el per neuron and grid block size\n",
    "    FFI_PER_NEURON: tl.constexpr,\n",
    "    BLOCK_SIZE_X: tl.constexpr,\n",
    "    BLOCK_SIZE_Y: tl.constexpr,\n",
    "):\n",
    "    block_idx_x, block_idx_y = tl.program_id(axis=0), tl.program_id(axis=1)\n",
    "    batch_idx = block_idx_x * BLOCK_SIZE_X\n",
    "    unit_idx = block_idx_y * BLOCK_SIZE_Y\n",
    "\n",
    "    batch_offsets = batch_idx + tl.arange(0, BLOCK_SIZE_X)\n",
    "\n",
    "    unit_offsets = unit_idx + tl.arange(0, BLOCK_SIZE_Y)\n",
    "    unit_mask = unit_offsets < n_out * n_batch\n",
    "\n",
    "    mask_offsets = tl.expand_dims(\n",
    "        unit_offsets, 1\n",
    "    ) * FFI_PER_NEURON + tl.expand_dims(tl.arange(0, FFI_PER_NEURON), 0)\n",
    "    mask_mask = mask_offsets < n_weights\n",
    "    weight_offsets = (\n",
    "        tl.expand_dims(tl.arange(0, FFI_PER_NEURON), 1)\n",
    "        + tl.expand_dims(unit_offsets, 0) * FFI_PER_NEURON\n",
    "    )\n",
    "    weight_mask = weight_offsets < n_weights\n",
    "\n",
    "    output_offsets = tl.expand_dims(\n",
    "        batch_offsets * BLOCK_SIZE_X, 1\n",
    "    ) + tl.expand_dims(unit_offsets, 0)\n",
    "    output_mask = output_offsets < n_batch * n_out\n",
    "\n",
    "    bias = tl.load(bias_p + unit_offsets, mask=unit_mask)\n",
    "    output = tl.load(output_p + output_offsets, output_mask)\n",
    "    output += bias\n",
    "    weights = tl.load(weight_p + weight_offsets, mask=weight_mask)\n",
    "    mask = tl.load(mask_p + mask_offsets, mask=mask_mask)\n",
    "\n",
    "    input_offset = tl.expand_dims(batch_offsets, 1) * n_in + mask\n",
    "    input_mask = input_offset < n_in * n_batch\n",
    "    inputs = tl.load(input_p + input_offset, input_mask)\n",
    "    output+=tl.dot(inputs, weights, allow_tf32=False)\n",
    "    tl.store(output_p + output_offsets, output, output_mask)\n",
    "\n",
    "\n",
    "# output = torch.zeros(size=(__BATCH_SIZE, __OUTPUT_DIM), device=__DEVICE)\n",
    "output = torch.zeros(size=(32, 32), device=__DEVICE)\n",
    "input = x[:32]\n",
    "weight = ffi_vmap.condensed_weight.T[:,:32] # shape is now ffi, output\n",
    "bias = ffi_vmap.bias[:32]\n",
    "mask = ffi_vmap.input_mask[:, :32]\n",
    "n_elements = input.numel()\n",
    "n_weights = weight.numel()\n",
    "FFI_PER_NEURON = weight.shape[0]  # first dim is now ffi\n",
    "BLOCK_SIZE_X=32\n",
    "BLOCK_SIZE_Y=32\n",
    "n_out = __OUTPUT_DIM\n",
    "n_in = __INPUT_DIM\n",
    "n_batch = __BATCH_SIZE\n",
    "grid = triton.cdiv(input.shape[0], BLOCK_SIZE_X), triton.cdiv(weight.shape[1], BLOCK_SIZE_Y)  # 32 threads per grid block \n",
    "print(grid)\n",
    "ffi_triton[grid](output, input, weight, bias, mask, n_out, n_in, n_batch, n_weights, FFI_PER_NEURON, BLOCK_SIZE_X, BLOCK_SIZE_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1232, -0.0895,  0.0676,  ..., -0.0246, -0.0354,  0.1017],\n",
       "        [ 0.0760,  0.0181,  0.0712,  ...,  0.0764, -0.0776,  0.0032],\n",
       "        [ 0.0138,  0.0364,  0.0373,  ..., -0.0172, -0.0130, -0.0309],\n",
       "        ...,\n",
       "        [ 0.0413,  0.0363,  0.0045,  ...,  0.0211, -0.0203,  0.0484],\n",
       "        [ 0.0308, -0.0146,  0.0493,  ...,  0.0342, -0.1280,  0.0263],\n",
       "        [ 0.0217, -0.0331,  0.0143,  ...,  0.0113, -0.0115,  0.0393]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1232,  0.0130,  0.0503,  ...,  0.0044,  0.1327, -0.0037],\n",
       "        [ 0.0611,  0.0181,  0.0692,  ..., -0.0472, -0.0061,  0.0579],\n",
       "        [ 0.0146,  0.0054,  0.0373,  ..., -0.0691,  0.0511,  0.0396],\n",
       "        ...,\n",
       "        [ 0.0471, -0.0160,  0.0714,  ...,  0.0009,  0.0314, -0.0287],\n",
       "        [ 0.0535, -0.0362,  0.0113,  ..., -0.0411,  0.0465,  0.0367],\n",
       "        [ 0.0417, -0.0522,  0.0295,  ..., -0.0239,  0.0364,  0.0108]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffi_compiled(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4096])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8160/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8160, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output!=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedFanInCuda(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        dtype: torch.typename = torch.float32,\n",
    "        transpose: bool = True,\n",
    "        vectorize: bool = False,\n",
    "        index_dtype: torch.typename = torch.int32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if dtype is None:\n",
    "            dtype = module.weight.dtype\n",
    "\n",
    "        self.transpose = transpose\n",
    "        with torch.no_grad():\n",
    "            active_neuron_idx = module.weight.sum(dim=1) != 0\n",
    "            fine_grained_idx = (module.weight[active_neuron_idx] != 0).to(\n",
    "                torch.bool\n",
    "            )\n",
    "            _, self.input_mask = fine_grained_idx.nonzero(as_tuple=True)\n",
    "            self.input_mask = self.input_mask.reshape(\n",
    "                shape=(module.weight[active_neuron_idx].shape[0], -1)\n",
    "            ).to(index_dtype)\n",
    "            weight = module.weight[active_neuron_idx].detach().type(dtype)\n",
    "            weight = torch.clone(\n",
    "                weight[fine_grained_idx]\n",
    "                .reshape(shape=(weight.shape[0], -1))\n",
    "                .detach()\n",
    "                .type(dtype)\n",
    "            )\n",
    "            # padding to multiple of 4\n",
    "            if vectorize:\n",
    "                pad = (\n",
    "                    self.input_mask.shape[1] + 3\n",
    "                ) // 4 * 4 - self.input_mask.shape[1]\n",
    "                self.input_mask = F.pad(self.input_mask, [0, pad])\n",
    "                weight = F.pad(weight, [0, pad])\n",
    "\n",
    "            self.condensed_weight = nn.Parameter(\n",
    "                weight,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "\n",
    "            if hasattr(module, \"bias\"):\n",
    "                self.bias = nn.Parameter(\n",
    "                    torch.clone(\n",
    "                        module.bias[active_neuron_idx].detach().type(dtype)\n",
    "                    ),\n",
    "                    requires_grad=False,\n",
    "                )\n",
    "            else:\n",
    "                self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return ffi_mul(\n",
    "            input,\n",
    "            self.condensed_weight,\n",
    "            self.input_mask,\n",
    "            self.bias,\n",
    "            transpose=self.transpose,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondensedLinearFineGrained(nn.Module):\n",
    "    def __init__(\n",
    "        self, module: nn.Module, dtype: torch.typename = torch.float32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if dtype is None:\n",
    "            dtype = module.weight.dtype\n",
    "        with torch.no_grad():\n",
    "            active_neuron_idx = module.weight.sum(dim=1) != 0\n",
    "            fine_grained_idx = (module.weight[active_neuron_idx] != 0).to(\n",
    "                torch.bool\n",
    "            )\n",
    "            _, self.input_mask = fine_grained_idx.nonzero(as_tuple=True)\n",
    "            self.input_mask = self.input_mask.reshape(\n",
    "                shape=(module.weight[active_neuron_idx].shape[0], -1)\n",
    "            )\n",
    "            self.input_mask = self.input_mask.to(torch.int32)\n",
    "            weight = module.weight[active_neuron_idx].detach().type(dtype)\n",
    "            self.condensed_weight = nn.Parameter(\n",
    "                torch.clone(\n",
    "                    weight[fine_grained_idx]\n",
    "                    .reshape(shape=(weight.shape[0], -1))\n",
    "                    .detach()\n",
    "                    .type(dtype)\n",
    "                ),\n",
    "                requires_grad=False,\n",
    "            )\n",
    "            if hasattr(module, \"bias\"):\n",
    "                self.bias = nn.Parameter(\n",
    "                    torch.clone(\n",
    "                        module.bias[active_neuron_idx].detach().type(dtype)\n",
    "                    ),\n",
    "                    requires_grad=False,\n",
    "                )\n",
    "            else:\n",
    "                self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return (\n",
    "            torch.sum(\n",
    "                self.condensed_weight * input[..., self.input_mask],\n",
    "                dim=input.dim(),\n",
    "            )\n",
    "            + self.bias\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
